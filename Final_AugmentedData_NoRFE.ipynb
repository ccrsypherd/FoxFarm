{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccrsypherd/FoxFarm/blob/main/Final_AugmentedData_NoRFE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrdEAfs1i4E7",
        "outputId": "975442de-994b-47af-940e-d35dd438650e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nilearn in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.2.0)\n",
            "Requirement already satisfied: requests>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (2.27.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nilearn) (23.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nilearn) (4.9.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.22.4)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.5.3)\n",
            "Requirement already satisfied: nibabel>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (5.1.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->nilearn) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->nilearn) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (2.0.12)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->nilearn) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.1.5->nilearn) (1.16.0)\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "### Initialize ###\n",
        "\n",
        "!pip install nilearn\n",
        "import warnings\n",
        "from nilearn.connectome import ConnectivityMeasure\n",
        "# ignore the warning message from nilearn\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from nilearn.connectome import ConnectivityMeasure\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Define the paths to the data folders\n",
        "data_dir = '/content/gdrive/MyDrive/ds18/smalldense/'\n",
        "class_folders = os.listdir(data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Load Original Data and Labels ###\n",
        "# Initialize empty lists for data and labels\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "# Loop over the class folders\n",
        "for i, class_folder in enumerate(class_folders):\n",
        "    class_path = os.path.join(data_dir, class_folder)\n",
        "    file_names = os.listdir(class_path)\n",
        "    \n",
        "    # Loop over the files in the class folder\n",
        "    for file_name in file_names:\n",
        "        if file_name.endswith('.dot'):\n",
        "            file_path = os.path.join(class_path, file_name)\n",
        "            with open(file_path, 'r') as f:\n",
        "                file_contents = np.load(file_path)\n",
        "                # Append the file contents to the data list\n",
        "                data.append(file_contents)\n",
        "                # Append the class label to the labels list\n",
        "                labels.append(i)\n",
        "# Convert the data and labels to numpy arrays\n",
        "data = np.array(data)\n",
        "print(data.shape)\n",
        "labels = np.array(labels)\n",
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrQAtNrG3mBH",
        "outputId": "d56b0580-ab2e-43c4-f863-1c8881b0ffb5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30, 3001, 3001)\n",
            "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QppqPlZVisfG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6691655f-dfd6-4a12-e363-d7ebcaaa8391"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(90, 3001, 3001)\n",
            "(90, 9006001)\n"
          ]
        }
      ],
      "source": [
        "# Define the amount of perturbation to apply to each matrix\n",
        "perturbation_scale = 0.01\n",
        "\n",
        "# Define the number of new matrices to create by perturbing each original matrix\n",
        "num_augmentations = 3\n",
        "\n",
        "# Initialize empty arrays to hold the augmented data and labels\n",
        "augmented_data = np.zeros((data.shape[0] * num_augmentations, data.shape[1], data.shape[2]))\n",
        "augmented_labels = np.zeros((data.shape[0] * num_augmentations,), dtype=labels.dtype)\n",
        "\n",
        "# Loop over each matrix in the original dataset\n",
        "for i in range(data.shape[0]):\n",
        "    # Add random noise to create multiple new matrices\n",
        "    for j in range(num_augmentations):\n",
        "        perturbation = perturbation_scale * np.random.randn(data.shape[1], data.shape[2])\n",
        "        new_matrix = data[i] + perturbation\n",
        "        augmented_data[i*num_augmentations+j] = new_matrix\n",
        "        augmented_labels[i*num_augmentations+j] = labels[i]\n",
        "\n",
        "# Check the shape of the combined dataset\n",
        "print(augmented_data.shape)  # Output: (120, 3001, 3001)\n",
        "\n",
        "# The augmented data will now contain (30 * num_augmentations) matrices, with corresponding labels\n",
        "del data\n",
        "del labels\n",
        "\n",
        "# Flatten each correlation matrix into a one-dimensional array\n",
        "feature_vectors = augmented_data.reshape(augmented_data.shape[0], -1)\n",
        "print(feature_vectors.shape)\n",
        "del augmented_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### Apply SVM Directly to the Flattened Matrices of 900301 ###\n",
        "\n",
        "# Define kernel values to loop over\n",
        "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "\n",
        "# Define number of iterations\n",
        "num_iterations = 5\n",
        "\n",
        "# Initialize results array\n",
        "results = np.zeros((num_iterations, 5))\n",
        "\n",
        "# Loop over different kernel values\n",
        "for kernel in kernels:\n",
        "    # Loop over iterations\n",
        "    for i in range(num_iterations):\n",
        "        print(i)\n",
        "        # Split data into training and testing sets\n",
        "        X_train, X_test, y_train, y_test = train_test_split(feature_vectors, augmented_labels, test_size=0.2)\n",
        "\n",
        "        # Train SVM classifier\n",
        "        svm = SVC(kernel=kernel)\n",
        "\n",
        "        # Fit model and make predictions\n",
        "        svm.fit(X_train, y_train)\n",
        "        y_pred = svm.predict(X_test)\n",
        "\n",
        "        # Calculate metrics and store in results array\n",
        "        results[i][0] = accuracy_score(y_train, svm.predict(X_train))\n",
        "        results[i][1] = accuracy_score(y_test, y_pred)\n",
        "        results[i][2] = precision_score(y_test, y_pred, average='macro')\n",
        "        results[i][3] = recall_score(y_test, y_pred, average='macro')\n",
        "        results[i][4] = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "    # Print results for each kernel\n",
        "    print(f'Kernel: {kernel}')\n",
        "    print(f'{\"Training Accuracy\":<10} {\"Testing Accuracy\":<10} {\"Precision\":<10} {\"Recall\":<10} {\"F1 Score\":<10}')\n",
        "    for i in range(num_iterations):\n",
        "        print(f'{results[i][0]:<10.3f} {results[i][1]:<10.3f} {results[i][2]:<10.3f} {results[i][3]:<10.3f} {results[i][4]:<10.3f}')\n",
        "    print(f'Mean:      {np.mean(results[:, 0]):<10.3f} {np.mean(results[:, 1]):<10.3f} {np.mean(results[:, 2]):<10.3f} {np.mean(results[:, 3]):<10.3f} {np.mean(results[:, 4]):<10.3f}')\n",
        "    print('-------------------------------------------------------')"
      ],
      "metadata": {
        "id": "n42EoyA8dJXp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d5ea9f2-eaa7-498e-d551-dfc06e1a98ec"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "Kernel: linear\n",
            "Training Accuracy Testing Accuracy Precision  Recall     F1 Score  \n",
            "1.000      1.000      1.000      1.000      1.000     \n",
            "1.000      1.000      1.000      1.000      1.000     \n",
            "1.000      1.000      1.000      1.000      1.000     \n",
            "1.000      1.000      1.000      1.000      1.000     \n",
            "1.000      0.833      0.889      0.900      0.875     \n",
            "Mean:      1.000      0.967      0.978      0.980      0.975     \n",
            "-------------------------------------------------------\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "Kernel: poly\n",
            "Training Accuracy Testing Accuracy Precision  Recall     F1 Score  \n",
            "0.847      0.944      0.967      0.944      0.952     \n",
            "0.792      0.833      0.900      0.822      0.837     \n",
            "0.806      0.944      0.952      0.917      0.927     \n",
            "0.792      0.833      0.875      0.875      0.846     \n",
            "0.819      0.722      0.861      0.689      0.703     \n",
            "Mean:      0.811      0.856      0.911      0.849      0.853     \n",
            "-------------------------------------------------------\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "Kernel: rbf\n",
            "Training Accuracy Testing Accuracy Precision  Recall     F1 Score  \n",
            "0.917      1.000      1.000      1.000      1.000     \n",
            "0.931      0.944      0.933      0.944      0.933     \n",
            "0.917      1.000      1.000      1.000      1.000     \n",
            "0.917      1.000      1.000      1.000      1.000     \n",
            "0.944      0.722      0.676      0.685      0.641     \n",
            "Mean:      0.925      0.933      0.922      0.926      0.915     \n",
            "-------------------------------------------------------\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "Kernel: sigmoid\n",
            "Training Accuracy Testing Accuracy Precision  Recall     F1 Score  \n",
            "0.903      0.889      0.905      0.926      0.903     \n",
            "0.889      0.778      0.833      0.852      0.794     \n",
            "0.889      0.944      0.958      0.917      0.930     \n",
            "0.931      0.778      0.806      0.790      0.771     \n",
            "0.847      0.611      0.821      0.741      0.665     \n",
            "Mean:      0.892      0.800      0.864      0.845      0.812     \n",
            "-------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######## t-SNE Data to 2D to Visualize SVM #########\n",
        "num_iterations = 10\n",
        "# Define colors for each class\n",
        "colors = ['yellow', 'green', 'red']\n",
        "class_labels = ['Control', 'Tame', 'Aggressive']\n",
        "\n",
        "# Define perplexity and kernel values to loop over\n",
        "perplexities = [5, 10, 15]\n",
        "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "\n",
        "# Loop over different perplexity and kernel values\n",
        "for perplexity in perplexities:\n",
        "    singleplot = 1\n",
        "    for kernel in kernels:\n",
        "        # Perform t-SNE\n",
        "        tsne = TSNE(n_components=2, perplexity=perplexity, random_state = 1)\n",
        "        X_2d = tsne.fit_transform(feature_vectors)\n",
        "        \n",
        "        # Print results for each kernel\n",
        "        print(f'Kernel: {kernel}')\n",
        "        print(f'Perplexity: {perplexity}')\n",
        "\n",
        "        for i in range(num_iterations):\n",
        "        \n",
        "            # Split data into training and testing sets\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X_2d, augmented_labels, test_size=0.2)\n",
        "\n",
        "            # Fit model and make predictions\n",
        "            svm.fit(X_train, y_train)\n",
        "            y_pred = svm.predict(X_test)\n",
        "\n",
        "            # Calculate metrics and store in results array\n",
        "            results[i][0] = accuracy_score(y_train, svm.predict(X_train))\n",
        "            results[i][1] = accuracy_score(y_test, y_pred)\n",
        "            \n",
        "        print(f'Mean:      {np.mean(results[:, 0]):<10.3f} {np.mean(results[:, 1]):<10.3f}')    \n",
        "        print('-------------------------------------------------------')\n",
        "\n",
        "        # Plot decision boundary and scatter plot\n",
        "        xx, yy = np.meshgrid(np.linspace(X_2d[:, 0].min()-1, X_2d[:, 0].max()+1, 100),\n",
        "                             np.linspace(X_2d[:, 1].min()-1, X_2d[:, 1].max()+1, 100))\n",
        "        Z = svm.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "        Z = Z.reshape(xx.shape)\n",
        "\n",
        "        plt.figure(figsize=(8, 8))\n",
        "        plt.gca().set_facecolor('honeydew') # set background color\n",
        "        plt.contourf(xx, yy, Z, alpha=0.4, cmap=ListedColormap(['forestgreen','gold','lightblue','lightcoral','gray']), levels=[-1,0,1])\n",
        "        plt.xlabel('Feature 1')\n",
        "        plt.ylabel('Feature 2')\n",
        "        plt.title('SVM classifier on t-SNE features\\nPerplexity: {}, Kernel: {}, Accuracy: {:.2f}'.format(perplexity, kernel, np.mean(results[:, 1])))\n",
        "\n",
        "        scatter_train = plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=ListedColormap(colors), alpha=0.8, edgecolors='none')\n",
        "        scatter_test = plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=ListedColormap(colors), alpha=0.8, edgecolors='k')\n",
        "        \n",
        "        handles_train, labels_train = scatter_train.legend_elements()\n",
        "        handles_test, labels_test = scatter_test.legend_elements()\n",
        "        plt.legend(handles_train + handles_test, class_labels, loc='upper left')\n",
        "\n",
        "        # Save figure to file\n",
        "        plt.savefig('ADataNoRFE_perp{}_kernel{}.png'.format(perplexity, kernel))"
      ],
      "metadata": {
        "id": "GDfHzIS0ZW2v"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyNRimegX3jrnx8KkBzKGxLM",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}